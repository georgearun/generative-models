
## Preliminary 

- **Bayesian Rule**: p(z|x)= p(x|z) p(z) /p(x)
- **Prior Distribution**: "often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account." (e.g. p(z)) 
- **Posterior Distribution:** is a probability distribution that represents your updated beliefs about the parameter after having seen the data. (e.g. p(z|x))
- **Posterior probability = prior probability + new evidence (called likelihood)**
- **Probability Density Function (PDF)**: the set of possible values taken by the random variable
- **Gaussian (Normal) Distribution**: A symmetrical data distribution, where most of the results lie near the mean.
- **Bayesian Analysis**:
  - Prior distribution: p(z)
  - Gather data
  - "Update your prior distribution with the data using Bayes' theorem to obtain a posterior distribution."
  - "Analyze the posterior distribution and summarize it (mean, median, etc.)"
- It is expected that you have knowledge of neural network concept (gradient descent, cost function, activation functions, regression, classification)
  - Typically used for regression or classification
  - Basically: fit(X,Y) and predict(X)

- [Notes on some basic probability stuff](./some_probability_stuff.pdf)

## Generative models

[The gradient of a model is ‘how the output changes when we change the parameters’](https://medium.com/@llionj/the-reparameterization-trick-4ff30fe92954)

## Other's Collections

- [Agustinus Kristiadi's Blog](http://wiseodd.github.io)

